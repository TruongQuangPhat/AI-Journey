{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e66ad44",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "#### What is Gradient Descent?\n",
    "- Gradient descent is an iterative optimization algorithm used to minimize a loss function, which represents how far the modelâ€™s predictions are from the actual values. The main goal is to adjust the parameters of a model (weights, biases, etc.) so that the error is minimized.\n",
    "- The update rule for the traditional gradient descent algorithm is:\n",
    "  $$\n",
    "  \\theta = \\theta - \\alpha \\nabla_{\\theta}J(\\theta)\n",
    "  $$\n",
    "- In traditional gradient descent, the gradients are computed based on the entire dataset, which can be computationally expensive for large datasets.\n",
    "#### Need for Stochastic Gradient Descent\n",
    "For large datasets, computing the gradient using all data points can be slow and memory-intensive. This is where SGD comes into play. Instead of using the full dataset to compute the gradient at each step, SGD uses only one random data point (or a small batch of data points) at each iteration. This makes the computation much faster.\n",
    "\n",
    "<img src=\"Images/stochastic.webp\" width=600>\n",
    "\n",
    "#### Working of Stochastic Gradient Descent\n",
    "- In Stochastic Gradient Descent, the gradient is caculated for each training example (or small subsets of training examples) rather than the entire dataset.\n",
    "- The update rule becomes:\n",
    "  $$\n",
    "  \\theta = \\theta - \\alpha \\nabla J(\\theta, x_{i}, y_{i})\n",
    "  $$\n",
    "  Where\n",
    "  - $x_{i}$ and $y_{i}$ represent the features and target of the i-th training example.\n",
    "  - The gradient $\\nabla J(\\theta, x_{i}, y_{i})$ is now caculated for a single data point or a small batch.\n",
    "- The key difference from traditional gradient descent is that, in SGD, the paramaters updates are made based on a single data point, not the entire dataset. The ramdom selection of data points introduces stochasticity, which can be both and advantage and a challenge.\n",
    "#### Advantages of Stochastic Gradient Descent\n",
    "1. `Efficiency`: Because it uses only one or a few data points to calculate the gradient, SGD can be much faster, especially for large datasets. Each step requires fewer computations, leading to quicker convergence.\n",
    "\n",
    "2. `Memory Efficiency`: Since it does not require storing the entire dataset in memory for each iteration, SGD can handle much larger datasets than traditional gradient descent.\n",
    "\n",
    "3. `Escaping Local Minima`: The noisy updates in SGD, caused by the stochastic nature of the algorithm, can help the model escape local minima or saddle points, potentially leading to better solutions in non-convex optimization problems (common in deep learning).\n",
    "\n",
    "4. `Online Learning`: SGD is well-suited for online learning, where the model is trained incrementally as new data comes in, rather than on a static dataset.\n",
    "#### Challenges of Stochastic Gradient Descent\n",
    "1. `Noisy Convergence`: Since the gradient is estimated based on a single data point (or a small batch), the updates can be noisy, causing the cost function to fluctuate rather than steadily decrease. This makes convergence slower and more erratic than in batch gradient descent.\n",
    "\n",
    "2. `Learning Rate Tuning`: SGD is highly sensitive to the choice of learning rate. A learning rate that is too large may cause the algorithm to diverge, while one that is too small can slow down convergence. Adaptive methods like Adam and RMSprop address this by adjusting the learning rate dynamically during training.\n",
    "\n",
    "3. `Long Training Times`: While each individual update is fast, the convergence might take a longer time overall since the steps are more erratic compared to batch gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a14810",
   "metadata": {},
   "source": [
    "### Momemtum\n",
    "#### What is Momentum?\n",
    "Momentum is an optimization technique that accelerates gradient descent by accumulating a velocity vector in directions of persistent reduction of the loss function. Instead of relying only on the current gradient, momentum combines the current gradient with a fraction of the previous update. This help smooth out oscillations and speed up convergence, especially in ravines or areas with high curvature.\n",
    "\n",
    "#### Update Rule\n",
    "The update equations with momentum are:\n",
    "  $$\n",
    "  v_{t} = \\beta v_{t - 1} + (1 - \\beta) \\nabla_{\\theta}J(\\theta)\n",
    "  $$\n",
    "  $$\n",
    "  \\theta = \\theta - \\alpha v_{t}\n",
    "  $$\n",
    "  Where:  \n",
    "  - $v_{t}$: velocity (accumulated gradient) at step $t$  \n",
    "  - $\\beta$: momentum coefficient ($0 \\leq \\beta < 1$), usually set around **0.9**  \n",
    "  - $\\alpha$: learning rate  \n",
    "  - $\\nabla_{\\theta}J(\\theta)$: gradient of the loss function w.r.t parameters  \n",
    "\n",
    "Intuition: $v_{t}$ acts like the \"inertia\" that carries information from past gradients. If the gradient points in the same direction repeatedly, $v_{t}$ grows, making updates faster in that direction. If gradient oscillate, momentum helps dampen the oscillations.\n",
    "\n",
    "#### Advantages of Momentum\n",
    "1. `Faster Convergence`: Accelerates learning, especially in directions where gradients consistently point the same way.\n",
    "2. `Reduced Oscillation`: Helps smooth noisy updates, particularly in SGD.\n",
    "3. `Effective in Ravines`: Deals well with cost function having steep curvature in one direction and shallow curvature in another.\n",
    "4. `Simple to implement`: Only requires storing the previous velocity vector.\n",
    "#### Challenges of Momentum\n",
    "1. `Hyperparameter Tuning`: The choice of $\\beta$ is critical. Too high can overshoot minima, too low loses the benifit.\n",
    "2. `Risk of Overshooting`: If combined with a large learning rate, the accumulated velocity may push parameters past the optimal point.\n",
    "3. `Not Adaptive`: Momentum dose not adjust learning rates for individual parameters like Adam or RMSprop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
